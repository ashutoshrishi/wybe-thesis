\chapter{Wybemk, Compiler and Build System}
\label{chap:build_system}

\textbf{Wybemk} is the incremental compiler and a Make utility combined
together in one executable for Wybe source code. It is modelled after the GNU
Make utility \citep{make}, but doesn't need an explicit \textit{Makefile} to
make Wybe source files. The Wybemk compiler just needs the name of a target to
build, and it will infer the building and linking order. Targets include
architecture dependant relocatable object files, LLVM bitcode files, or a final
linked executable. The object files and bitcode files that Wybemk builds are a
little different than what other utilities create. They have embedded
information that assists a future compilation processes in being
incremental. It is this embedding that allows Wybemk to be an incremental and
work-saving compiler.

By not building a target object file when the source is older, the LPVM form
and analysis for that module is also skipped. This is acceptable for only
intra-module optimisations, since the final optimised object code will be the
same. But we might be missing a lot of inter module optimisation opportunities
and LPVM inlining that other dependant modules can reap benefits from. Object
files store a symbol table which will list all the callable function names in
it. This is what the \textit{linker} uses to resolve extern calls during
linking. The body of these functions are stored in object code form. We can't
make a decision on inlining these functions into another module from this. It
would be beneficial to have the LPVM form of all the modules participating in a
compilation process for these optimisation decisions. We want to store LPVM
analysis information in the object files so that when they are not going to be
re-compiled, we can at least pull in the LPVM form of that module in the
compilation pipeline.

The limited structure of LPVM makes serialising and embedding its byte
structure into a object file byte string easy and feasibile. We could have also
stored the parse tree, but a parse tree has a wider form and is redundant with
the source code. With storing the parse tree we are only skipping the work the
parser does and would have to redo all the LPVM transformation and
analysis. This would be more work. The simple yet highly informational form of
LPVM makes it an ideal structure to pass around.


Why object files though? An object files' structure is architecture dependent
and requires different efforts for storing and loading information for each
architecture. This would put a constraint on the number of architectures that
Wybemk can operate on even though with LLVM it should be able to possibly
generate code for those architectures. However object files are a common
container for relocatable machine code. Most compilers traditionally build a
object file for the linker to link. Currently Wybemk does not want to reinvent
that format and we would like our incremental features to work in tandem with
the common choices. Apart from object files however, the Wybemk compiler can do
the same embedding with LLVM bitcode files. LLVM bitcode files can be treated
as architecture neutral, and since we use a LLVM compiler as a final stage, we
can use bitcode files as a replacement for architecture dependent object files.


\section{Storing structures in Object files}

Object files store relocatable object code which is the compiled code generated
by the LLVM compiler in the wybe compiler. Even though different architectures
have their own specification of the object file format, they are modelled
around the same basic structure. Object files defines segments, which are
mapped as memory segments during linking and loading. A special segment called
\textit{TEXT} usually contains the instructions. An object file also lists the
symbols defined in it, which is useful for the linker to resolve external
function calls from another module being linked. Avoiding all the common
segment names, it is possible to add new segments to the object file (at the
correct byte offset), which do not get mapped to memory. These are zero address
segments. Using such such segment we can attempt storage of some useful
serialised meta-data in the object file. 

Our current implementation has the functionality to parse and embed information
in \macho object files and \textit{bitcode} files. The \macho file format is
the Application Binary Interface (ABI) format that the OS X operating system
uses for its object files. An ABI describes the byte ordering and their meaning
for the operating system in this case. The embedded bytes do not interfere in
any semantics of the object file. It still appears as an ordinary object file
to every other machine utility or parser, like the tools \textit{ld}, and
\textit{nm}. The only aspect which noticeably changes is it's total byte size.


\subsection{Mach-O Object File Format}

Quite simply, an object file is a long byte string sequence. Referring to the
Apple documentation\footnotemark on their format, we are able to parse and
edit the \macho byte structure. The first 32 bits or 4 bytes are considered to
be the magic number if read in little endian format. The magic number constant
determines what kind of ABI the rest of the bytes of the file follow and their
ordering. On OS X we can have 32 bit and 64 bit \macho object files and
Universal binaries. Universal binaries or Fat archives contain more than one
object file. Wybemk is interested in \macho object files.


The header bytes of the identified structure will give the number of load
commands the file contains. The load commands are the segments which get loaded
to the main memory during execution. The load commands provide the name of
their segment and a pointer to offset of their data. Each segment can also
contain multiple sections. Wybemk creates a new segment called
\textit{\textunderscore \textunderscore LPVM} and a section in it called
\textit{\textunderscore \textunderscore lpvm}, following naming
conventions. Once the offsets are correctly determined and bytes describing the
load command put in its right place, we can insert any length byte-string at
our offset. This byte-string will be the encoded serialised form of our
embedded data.

While we have only covered the \macho object files in our embedding
implementation, it is also possible to use the system \textit{ld} linking,
found on most \textit{UNIX} OS, to add new segments and sections. Other object
file formats, like the \textit{Elf} format for Linux, can be used for embedding
this way. This is part of our future planned work.

\footnotetext{ Documentation \url{https://developer.apple.com/library/mac/documentation/DeveloperTools/Conceptual/MachORuntime/}}

\subsection{Bitcode Wrapper}

LLVM IR can be put in \textit{bitcode} files\footnotemark. These are binary
representations of the LLVM IR it encodes. These files are identified by a
magic number, similar to a \macho file. LLVM tools can easily generate these
formats and even compile them to object file and link them. In a way they are a
machine architecture independent version of object files and can be easily
distributed between compilers which support LLVM. It provides great
interoperability. Hence we want to have the option to utilise them in a similar
fashion to how we utilise object files.

A \textit{bitcode} wrapper differs from an ordinary \textit{bitcode} file in
its initial magic number. This wrapper format specifies a header which should
give the byte offset of the byte string representation of the LLVM IR it
holds. The rest of the bytes after the header and before the offset are
therefore free to embed information. We use this space to store our LPVM
information which usually goes into the object file.


\footnotetext{ See \url{http://llvm.org/docs/BitCodeFormat.html}}


\section{Incremental Compilation}

Wybe, as a programming language, wants to be useful for large scale
projects. Thus, it wants its compilation process to be as effecient as
possible. In larger projects, a large number of modules are involved in a
single build. Doing incremental builds would involve smaller changes being
added for every fresh build. Having all the modules compile again is a waste of
time. 

The goal is to make Wybemk incremental at multiple levels. This can be done by
identifying key stages of a compilation process which can act as save and
restore points. The saving is done in object files (or bitcode files) as shown
above. The decision to restore has to be a careful one, as a false positive
would result in a completely wrong build. There should be no margin for these
kinds of errors to exist if this compiler is to be used in production
builds. There is also a requirement of being incremental without losing the
benefits of LPVM optimisations. With these constraints, currently Wybemk has
two incremental and work saving approaches: Module level reloading, and storing
hashes of key compilation stages.


\subsection{Module level reloading}

Wybemk compiler behaves like GNU Make but it does not depend on Makefiles. It
infers the module dependancy graph and builds everything accordingly. It should
also link in standard libraries and external foreign libraries wherever
needed. Inferring the dependancy graph is done through parsing the top level
\textit{use module} statements. During compilation LPVM representation of each
module in the graph is built. For modules who have a newer object file, this
representation will be stored in a serialised form and has to be
\textit{reloaded} into the pipeline. This keeps the optimisations going and
allows other modules to inline functions or procedures from that module.

For example the \textit{int} module in the Wybe standard library module
(Figure~\ref{fig:wybe_int}) mostly has one line procedures and functions
(simple arithmetic operators pointing to LLVM instructions). That is, their
body is a single procedure call. Instances of calls to \textit{proc +} can be
replaced with the body proc call instead. And this is what actually happens
when the standard library object file is \textit{loaded} by the Wybemk
compiler. Inlining at LPVM level provides these small but essential benefits.

We want to embed only the minimum set of data we will need for the next
compilation. The serialised abstract data type in the implementation is the
subset of the type which holds information on the whole \textit{Module}. The
complete \textit{Module} type holds information on the exported types,
procedure implementations, sub-module names, dependency information, LLVM
implementation, among others. The serialised subset will remove local
information and just preserve the interface of the \textit{Module}. For
example, the LLVM implementation is already present in essence in the
\textit{TEXT} segment of the object file in object code form.

Not every procedure defined in the module has to have its LPVM form passed
along in the serialised \textit{Module}. Private procedures cannot be in-lined
by any other module and hence will never be utilised in an inter-module
optimisation. Serialising the LPVM form instead of the source code form already
saves a lot of space, having extra space saving heuristics is a bonus. The
exportable \textit{Module} subset is serialised as a byte string. A LPVM
primitive is made up of either of two constructors
(Figure~\ref{fig:lpvm_data_type}): \textit{PrimCall} or
\textit{PrimForeign}. This keeps the tag byte size small for serialising a
procedure body. Even the procedure LPVM implementation is made up of only one
constructor: \textit{ProcDefPrim}. The tag byte contains flag type information
to identify which constructor to use while decoding.



\subsection{Incrementality through Hashing}

Certain stages in the compilation pipeline can act as checkpoints where Wybemk
checks if it is going to do the same work as the last compilation. These
checkpoints have to be chosen carefully as having numerous checkpoints will
start slowing down the compiler instead of saving time. Certain stages behave
as natural checkpoints, like the end of the parsing and the end of
transformation to LPVM. For determining if Wybemk has reached the same stage as
before, it hashes the serialised form of the current representation at hand,
and compares it with the hash stored in the object file. Hence, along with the
serialised LPVM representation of module, Wybemk object file also embeds
certain hash strings in a serialised map data structure.

The constraints under which our system is to operate is similar to the ones
mentioned in \cite{cpp_compiler} for their C++ incremental compiler system. We
choose our granularity in such a way that we can automatically generate
dependencies for it. We have to absolutely sure we are not executing old code
and that we are choosing the right old versions. Their system uses time
stamping as a heuristic to choose between compiling or not, while we are using
hash comparisons to choose between compiling or loading.

These methods are meant to kick in for scenarios where the source file has more
edits (or is newer) than the object file. In these cases simply loading the
whole LPVM module is not correct. But identifying unchanged parts and loading
those parts while re-doing the other parts provide a faster compilation
time. In our current iteration of the compiler we are applying hash comparisons
at two stages: after parsing, and just before the LPVM optimisation passes.

After parsing we can store the hash of the parse tree generated by the
parser. When the parser finishes its work, Wybemk can hash its AST and compare
it with the hash of the previous AST. For source code edits involving changing
or adding comments and white-space, the parse tree doesn't change even though
the source file will now have a newer modification time. These trivial yet
extremely common edits should not run the whole compilation process. In this
case we just load the final LPVM form from the object file. A future extension
to this check is considering procedure, functions, and other top level items
without order, so that that they all are individually checked and changing
their order in the file changes nothing.

% Change this part it's rubbish
Completely change this last part.

The choice of granularity for the Wybemk compiler is a Wybe procedure or
function. As shown in chapter~\ref{chap:wybe_to_lpvm}, a Wybe procedure or
function is flattened to a procedure form very early in the compilation
pipeline. The dependency resolution is then narrowed to tracking the
relationship of these flattened procedures to the LPVM procedures they are
transformed to. A Wybe \textit{procedure A} depends on \textit{procedure B}, if
it contains a call to \textit{B}. Flattened Wybe procedure can be transformed
to one or more LPVM procedure.

If one procedure is changed, the only parts that should be recompiled is that
procedure itself and some other affected procedures (due to inlining or
calls). We can check for edits at the parse tree level (in Wybe form) or when
the LPVM form is generated (before optimisation passes). Checking the Wybe
source form coincides with the parse tree hashing we are doing above. Every
Wybe function or procedure is flattened to be a procedure, so when we talk
about procedures, we are considering all top level items in the module.

If we change a variable name uniformly throughout a procedure body, it's LPVM
form would not change since LPVM will be generating it's own unique variable
names. These kind of edits don't change the semantics of the procedure and
re-compilation is not needed. Hence, it is useful to check LPVM forms of a Wybe
procedure and on a successful match, we can skip the further optimisation
passes, loading the final form and object code for those procedures. A Wybe
procedure, when transformed to LPVM form, might create more than one LPVM
predicate or procedure. This happens for conditional branching and loops. This
mapping has to be tracked so that we know which LPVM procedures to load in.

%%% Local Variables:
%%% reftex-default-bibliography: ("../refs.bib")
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End:
